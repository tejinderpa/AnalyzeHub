{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejinderpa/AnalyzeHub/blob/main/lstm_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"Parallel lines have so much in common. It’s a shame.\\n\n",
        "Why don’t scientists trust atoms? They make up stuff.\\n\n",
        "I told my wife she was drawing her eyebrows too high.\\n\n",
        "She looked surprised.\\n\n",
        "I would tell you a construction joke, but I’m working on it.\\n\n",
        "Why did the scarecrow win an award? He was outstanding.\\n\n",
        "I used to play piano by ear. Now I use my hands.\\n\n",
        "What do you call fake spaghetti? An impasta.\\n\n",
        "I told my dog a joke about bones. He chewed it over.\\n\n",
        "Why can't you hear a pterodactyl in the bathroom?\\n\n",
        "Because the “P” is silent.\\n\n",
        "What do you call cheese that isn't yours? Nacho cheese.\\n\n",
        "I'm reading a book on anti-gravity. It's impossible to put down.\\n\n",
        "Why don’t skeletons fight each other? No guts.\\n\n",
        "I used to be addicted to soap. Now I’m clean.\\n\n",
        "Why don’t eggs tell jokes? They’d crack each other up.\\n\n",
        "I ordered a chicken and an egg online. I’ll let you know.\\n\n",
        "What's orange and sounds like a parrot? A carrot.\\n\n",
        "Why did the bicycle fall over? It was two-tired.\\n\n",
        "I have a fear of speed bumps. But I’m slowly getting over it.\\n\n",
        "Why can't your nose be 12 inches long? Then it’d be a foot.\\n\n",
        "I made a pencil with two erasers. It was pointless.\\n\n",
        "I stayed up all night to see where the sun went.\\n\n",
        "Then it dawned on me.\\n\n",
        "Why did the math book look sad? Too many problems.\\n\n",
        "I told my computer I needed a break. Now it won’t stop sending me beach photos.\\n\n",
        "I used to hate facial hair. Then it grew on me.\\n\n",
        "Why did the coffee file a police report? It got mugged.\\n\n",
        "What do you call a belt made of watches? A waist of time.\\n\n",
        "Did you hear about the claustrophobic astronaut?\\n\n",
        "He needed a little space.\\n\n",
        "Why was the stadium so cool? It was filled with fans.\\n\n",
        "I’m on a seafood diet. I see food and I eat it.\\n\n",
        "Why don't crabs give to charity? They’re shellfish.\\n\n",
        "How do cows stay up to date? They read the moos-paper.\\n\n",
        "Why did the golfer bring two pairs of pants?\\n\n",
        "In case he got a hole in one.\\n\n",
        "I tried to catch fog yesterday. Mist.\\n\n",
        "What did one wall say to the other wall? I’ll meet you at the corner.\\n\n",
        "Why did the cookie go to the hospital? It felt crummy.\\n\n",
        "What do you call a fish with no eyes? Fsh.\\n\n",
        "I only know 25 letters of the alphabet. I don’t know y.\\n\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "9632f55c-e6b1-4773-855a-02cc61b12f46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "9bd62f6f-80ad-495d-b0d1-b465c5c960bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[56, 57],\n",
              " [56, 57, 34],\n",
              " [56, 57, 34, 35],\n",
              " [56, 57, 34, 35, 58],\n",
              " [56, 57, 34, 35, 58, 14],\n",
              " [56, 57, 34, 35, 58, 14, 59],\n",
              " [56, 57, 34, 35, 58, 14, 59, 60],\n",
              " [56, 57, 34, 35, 58, 14, 59, 60, 1],\n",
              " [56, 57, 34, 35, 58, 14, 59, 60, 1, 61],\n",
              " [4, 15],\n",
              " [4, 15, 62],\n",
              " [4, 15, 62, 63],\n",
              " [4, 15, 62, 63, 64],\n",
              " [4, 15, 62, 63, 64, 36],\n",
              " [4, 15, 62, 63, 64, 36, 65],\n",
              " [4, 15, 62, 63, 64, 36, 65, 16],\n",
              " [4, 15, 62, 63, 64, 36, 65, 16, 66],\n",
              " [2, 21],\n",
              " [2, 21, 17],\n",
              " [2, 21, 17, 67],\n",
              " [2, 21, 17, 67, 37],\n",
              " [2, 21, 17, 67, 37, 9],\n",
              " [2, 21, 17, 67, 37, 9, 68],\n",
              " [2, 21, 17, 67, 37, 9, 68, 69],\n",
              " [2, 21, 17, 67, 37, 9, 68, 69, 70],\n",
              " [2, 21, 17, 67, 37, 9, 68, 69, 70, 38],\n",
              " [2, 21, 17, 67, 37, 9, 68, 69, 70, 38, 71],\n",
              " [37, 72],\n",
              " [37, 72, 73],\n",
              " [2, 74],\n",
              " [2, 74, 39],\n",
              " [2, 74, 39, 7],\n",
              " [2, 74, 39, 7, 1],\n",
              " [2, 74, 39, 7, 1, 75],\n",
              " [2, 74, 39, 7, 1, 75, 40],\n",
              " [2, 74, 39, 7, 1, 75, 40, 41],\n",
              " [2, 74, 39, 7, 1, 75, 40, 41, 18],\n",
              " [2, 74, 39, 7, 1, 75, 40, 41, 18, 76],\n",
              " [2, 74, 39, 7, 1, 75, 40, 41, 18, 76, 10],\n",
              " [2, 74, 39, 7, 1, 75, 40, 41, 18, 76, 10, 5],\n",
              " [4, 8],\n",
              " [4, 8, 3],\n",
              " [4, 8, 3, 77],\n",
              " [4, 8, 3, 77, 78],\n",
              " [4, 8, 3, 77, 78, 22],\n",
              " [4, 8, 3, 77, 78, 22, 79],\n",
              " [4, 8, 3, 77, 78, 22, 79, 19],\n",
              " [4, 8, 3, 77, 78, 22, 79, 19, 9],\n",
              " [4, 8, 3, 77, 78, 22, 79, 19, 9, 80],\n",
              " [2, 23],\n",
              " [2, 23, 6],\n",
              " [2, 23, 6, 81],\n",
              " [2, 23, 6, 81, 82],\n",
              " [2, 23, 6, 81, 82, 83],\n",
              " [2, 23, 6, 81, 82, 83, 84],\n",
              " [2, 23, 6, 81, 82, 83, 84, 24],\n",
              " [2, 23, 6, 81, 82, 83, 84, 24, 2],\n",
              " [2, 23, 6, 81, 82, 83, 84, 24, 2, 85],\n",
              " [2, 23, 6, 81, 82, 83, 84, 24, 2, 85, 17],\n",
              " [2, 23, 6, 81, 82, 83, 84, 24, 2, 85, 17, 86],\n",
              " [11, 12],\n",
              " [11, 12, 7],\n",
              " [11, 12, 7, 20],\n",
              " [11, 12, 7, 20, 87],\n",
              " [11, 12, 7, 20, 87, 88],\n",
              " [11, 12, 7, 20, 87, 88, 22],\n",
              " [11, 12, 7, 20, 87, 88, 22, 89],\n",
              " [2, 21],\n",
              " [2, 21, 17],\n",
              " [2, 21, 17, 90],\n",
              " [2, 21, 17, 90, 1],\n",
              " [2, 21, 17, 90, 1, 40],\n",
              " [2, 21, 17, 90, 1, 40, 42],\n",
              " [2, 21, 17, 90, 1, 40, 42, 91],\n",
              " [2, 21, 17, 90, 1, 40, 42, 91, 19],\n",
              " [2, 21, 17, 90, 1, 40, 42, 91, 19, 92],\n",
              " [2, 21, 17, 90, 1, 40, 42, 91, 19, 92, 5],\n",
              " [2, 21, 17, 90, 1, 40, 42, 91, 19, 92, 5, 25],\n",
              " [4, 43],\n",
              " [4, 43, 7],\n",
              " [4, 43, 7, 44],\n",
              " [4, 43, 7, 44, 1],\n",
              " [4, 43, 7, 44, 1, 93],\n",
              " [4, 43, 7, 44, 1, 93, 14],\n",
              " [4, 43, 7, 44, 1, 93, 14, 3],\n",
              " [4, 43, 7, 44, 1, 93, 14, 3, 94],\n",
              " [95, 3],\n",
              " [95, 3, 96],\n",
              " [95, 3, 96, 97],\n",
              " [95, 3, 96, 97, 98],\n",
              " [11, 12],\n",
              " [11, 12, 7],\n",
              " [11, 12, 7, 20],\n",
              " [11, 12, 7, 20, 45],\n",
              " [11, 12, 7, 20, 45, 99],\n",
              " [11, 12, 7, 20, 45, 99, 100],\n",
              " [11, 12, 7, 20, 45, 99, 100, 101],\n",
              " [11, 12, 7, 20, 45, 99, 100, 101, 102],\n",
              " [11, 12, 7, 20, 45, 99, 100, 101, 102, 45],\n",
              " [103, 104],\n",
              " [103, 104, 1],\n",
              " [103, 104, 1, 46],\n",
              " [103, 104, 1, 46, 10],\n",
              " [103, 104, 1, 46, 10, 105],\n",
              " [103, 104, 1, 46, 10, 105, 106],\n",
              " [103, 104, 1, 46, 10, 105, 106, 107],\n",
              " [103, 104, 1, 46, 10, 105, 106, 107, 108],\n",
              " [103, 104, 1, 46, 10, 105, 106, 107, 108, 6],\n",
              " [103, 104, 1, 46, 10, 105, 106, 107, 108, 6, 109],\n",
              " [103, 104, 1, 46, 10, 105, 106, 107, 108, 6, 109, 110],\n",
              " [4, 15],\n",
              " [4, 15, 111],\n",
              " [4, 15, 111, 112],\n",
              " [4, 15, 111, 112, 47],\n",
              " [4, 15, 111, 112, 47, 26],\n",
              " [4, 15, 111, 112, 47, 26, 48],\n",
              " [4, 15, 111, 112, 47, 26, 48, 113],\n",
              " [2, 23],\n",
              " [2, 23, 6],\n",
              " [2, 23, 6, 27],\n",
              " [2, 23, 6, 27, 114],\n",
              " [2, 23, 6, 27, 114, 6],\n",
              " [2, 23, 6, 27, 114, 6, 115],\n",
              " [2, 23, 6, 27, 114, 6, 115, 24],\n",
              " [2, 23, 6, 27, 114, 6, 115, 24, 18],\n",
              " [2, 23, 6, 27, 114, 6, 115, 24, 18, 116],\n",
              " [4, 15],\n",
              " [4, 15, 117],\n",
              " [4, 15, 117, 39],\n",
              " [4, 15, 117, 39, 118],\n",
              " [4, 15, 117, 39, 118, 119],\n",
              " [4, 15, 117, 39, 118, 119, 120],\n",
              " [4, 15, 117, 39, 118, 119, 120, 47],\n",
              " [4, 15, 117, 39, 118, 119, 120, 47, 26],\n",
              " [4, 15, 117, 39, 118, 119, 120, 47, 26, 16],\n",
              " [2, 121],\n",
              " [2, 121, 1],\n",
              " [2, 121, 1, 122],\n",
              " [2, 121, 1, 122, 28],\n",
              " [2, 121, 1, 122, 28, 22],\n",
              " [2, 121, 1, 122, 28, 22, 123],\n",
              " [2, 121, 1, 122, 28, 22, 123, 124],\n",
              " [2, 121, 1, 122, 28, 22, 123, 124, 49],\n",
              " [2, 121, 1, 122, 28, 22, 123, 124, 49, 125],\n",
              " [2, 121, 1, 122, 28, 22, 123, 124, 49, 125, 7],\n",
              " [2, 121, 1, 122, 28, 22, 123, 124, 49, 125, 7, 29],\n",
              " [126, 127],\n",
              " [126, 127, 28],\n",
              " [126, 127, 28, 128],\n",
              " [126, 127, 28, 128, 129],\n",
              " [126, 127, 28, 128, 129, 1],\n",
              " [126, 127, 28, 128, 129, 1, 130],\n",
              " [126, 127, 28, 128, 129, 1, 130, 1],\n",
              " [126, 127, 28, 128, 129, 1, 130, 1, 131],\n",
              " [4, 8],\n",
              " [4, 8, 3],\n",
              " [4, 8, 3, 132],\n",
              " [4, 8, 3, 132, 133],\n",
              " [4, 8, 3, 132, 133, 25],\n",
              " [4, 8, 3, 132, 133, 25, 5],\n",
              " [4, 8, 3, 132, 133, 25, 5, 9],\n",
              " [4, 8, 3, 132, 133, 25, 5, 9, 30],\n",
              " [4, 8, 3, 132, 133, 25, 5, 9, 30, 134],\n",
              " [2, 34],\n",
              " [2, 34, 1],\n",
              " [2, 34, 1, 135],\n",
              " [2, 34, 1, 135, 13],\n",
              " [2, 34, 1, 135, 13, 136],\n",
              " [2, 34, 1, 135, 13, 136, 137],\n",
              " [2, 34, 1, 135, 13, 136, 137, 41],\n",
              " [2, 34, 1, 135, 13, 136, 137, 41, 18],\n",
              " [2, 34, 1, 135, 13, 136, 137, 41, 18, 138],\n",
              " [2, 34, 1, 135, 13, 136, 137, 41, 18, 138, 139],\n",
              " [2, 34, 1, 135, 13, 136, 137, 41, 18, 138, 139, 25],\n",
              " [2, 34, 1, 135, 13, 136, 137, 41, 18, 138, 139, 25, 5],\n",
              " [4, 43],\n",
              " [4, 43, 140],\n",
              " [4, 43, 140, 141],\n",
              " [4, 43, 140, 141, 27],\n",
              " [4, 43, 140, 141, 27, 142],\n",
              " [4, 43, 140, 141, 27, 142, 143],\n",
              " [4, 43, 140, 141, 27, 142, 143, 144],\n",
              " [4, 43, 140, 141, 27, 142, 143, 144, 31],\n",
              " [4, 43, 140, 141, 27, 142, 143, 144, 31, 145],\n",
              " [4, 43, 140, 141, 27, 142, 143, 144, 31, 145, 27],\n",
              " [4, 43, 140, 141, 27, 142, 143, 144, 31, 145, 27, 1],\n",
              " [4, 43, 140, 141, 27, 142, 143, 144, 31, 145, 27, 1, 146],\n",
              " [2, 50],\n",
              " [2, 50, 1],\n",
              " [2, 50, 1, 147],\n",
              " [2, 50, 1, 147, 32],\n",
              " [2, 50, 1, 147, 32, 30],\n",
              " [2, 50, 1, 147, 32, 30, 148],\n",
              " [2, 50, 1, 147, 32, 30, 148, 5],\n",
              " [2, 50, 1, 147, 32, 30, 148, 5, 9],\n",
              " [2, 50, 1, 147, 32, 30, 148, 5, 9, 149],\n",
              " [2, 150],\n",
              " [2, 150, 16],\n",
              " [2, 150, 16, 151],\n",
              " [2, 150, 16, 151, 152],\n",
              " [2, 150, 16, 151, 152, 6],\n",
              " [2, 150, 16, 151, 152, 6, 51],\n",
              " [2, 150, 16, 151, 152, 6, 51, 153],\n",
              " [2, 150, 16, 151, 152, 6, 51, 153, 3],\n",
              " [2, 150, 16, 151, 152, 6, 51, 153, 3, 154],\n",
              " [2, 150, 16, 151, 152, 6, 51, 153, 3, 154, 155],\n",
              " [31, 5],\n",
              " [31, 5, 156],\n",
              " [31, 5, 156, 10],\n",
              " [31, 5, 156, 10, 33],\n",
              " [4, 8],\n",
              " [4, 8, 3],\n",
              " [4, 8, 3, 157],\n",
              " [4, 8, 3, 157, 46],\n",
              " [4, 8, 3, 157, 46, 158],\n",
              " [4, 8, 3, 157, 46, 158, 159],\n",
              " [4, 8, 3, 157, 46, 158, 159, 38],\n",
              " [4, 8, 3, 157, 46, 158, 159, 38, 160],\n",
              " [4, 8, 3, 157, 46, 158, 159, 38, 160, 161],\n",
              " [2, 21],\n",
              " [2, 21, 17],\n",
              " [2, 21, 17, 162],\n",
              " [2, 21, 17, 162, 2],\n",
              " [2, 21, 17, 162, 2, 52],\n",
              " [2, 21, 17, 162, 2, 52, 1],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5, 164],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5, 164, 165],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5, 164, 165, 166],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5, 164, 165, 166, 33],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5, 164, 165, 166, 33, 167],\n",
              " [2, 21, 17, 162, 2, 52, 1, 163, 24, 5, 164, 165, 166, 33, 167, 168],\n",
              " [2, 23],\n",
              " [2, 23, 6],\n",
              " [2, 23, 6, 169],\n",
              " [2, 23, 6, 169, 170],\n",
              " [2, 23, 6, 169, 170, 171],\n",
              " [2, 23, 6, 169, 170, 171, 31],\n",
              " [2, 23, 6, 169, 170, 171, 31, 5],\n",
              " [2, 23, 6, 169, 170, 171, 31, 5, 172],\n",
              " [2, 23, 6, 169, 170, 171, 31, 5, 172, 10],\n",
              " [2, 23, 6, 169, 170, 171, 31, 5, 172, 10, 33],\n",
              " [4, 8],\n",
              " [4, 8, 3],\n",
              " [4, 8, 3, 173],\n",
              " [4, 8, 3, 173, 174],\n",
              " [4, 8, 3, 173, 174, 1],\n",
              " [4, 8, 3, 173, 174, 1, 175],\n",
              " [4, 8, 3, 173, 174, 1, 175, 176],\n",
              " [4, 8, 3, 173, 174, 1, 175, 176, 5],\n",
              " [4, 8, 3, 173, 174, 1, 175, 176, 5, 53],\n",
              " [4, 8, 3, 173, 174, 1, 175, 176, 5, 53, 177],\n",
              " [11, 12],\n",
              " [11, 12, 7],\n",
              " [11, 12, 7, 20],\n",
              " [11, 12, 7, 20, 1],\n",
              " [11, 12, 7, 20, 1, 178],\n",
              " [11, 12, 7, 20, 1, 178, 50],\n",
              " [11, 12, 7, 20, 1, 178, 50, 13],\n",
              " [11, 12, 7, 20, 1, 178, 50, 13, 179],\n",
              " [11, 12, 7, 20, 1, 178, 50, 13, 179, 1],\n",
              " [11, 12, 7, 20, 1, 178, 50, 13, 179, 1, 180],\n",
              " [11, 12, 7, 20, 1, 178, 50, 13, 179, 1, 180, 13],\n",
              " [11, 12, 7, 20, 1, 178, 50, 13, 179, 1, 180, 13, 181],\n",
              " [8, 7],\n",
              " [8, 7, 44],\n",
              " [8, 7, 44, 42],\n",
              " [8, 7, 44, 42, 3],\n",
              " [8, 7, 44, 42, 3, 182],\n",
              " [8, 7, 44, 42, 3, 182, 183],\n",
              " [19, 52],\n",
              " [19, 52, 1],\n",
              " [19, 52, 1, 184],\n",
              " [19, 52, 1, 184, 185],\n",
              " [4, 9],\n",
              " [4, 9, 3],\n",
              " [4, 9, 3, 186],\n",
              " [4, 9, 3, 186, 35],\n",
              " [4, 9, 3, 186, 35, 187],\n",
              " [4, 9, 3, 186, 35, 187, 5],\n",
              " [4, 9, 3, 186, 35, 187, 5, 9],\n",
              " [4, 9, 3, 186, 35, 187, 5, 9, 188],\n",
              " [4, 9, 3, 186, 35, 187, 5, 9, 188, 32],\n",
              " [4, 9, 3, 186, 35, 187, 5, 9, 188, 32, 189],\n",
              " [18, 10],\n",
              " [18, 10, 1],\n",
              " [18, 10, 1, 190],\n",
              " [18, 10, 1, 190, 191],\n",
              " [18, 10, 1, 190, 191, 2],\n",
              " [18, 10, 1, 190, 191, 2, 51],\n",
              " [18, 10, 1, 190, 191, 2, 51, 192],\n",
              " [18, 10, 1, 190, 191, 2, 51, 192, 28],\n",
              " [18, 10, 1, 190, 191, 2, 51, 192, 28, 2],\n",
              " [18, 10, 1, 190, 191, 2, 51, 192, 28, 2, 193],\n",
              " [18, 10, 1, 190, 191, 2, 51, 192, 28, 2, 193, 5],\n",
              " [4, 194],\n",
              " [4, 194, 195],\n",
              " [4, 194, 195, 196],\n",
              " [4, 194, 195, 196, 6],\n",
              " [4, 194, 195, 196, 6, 197],\n",
              " [4, 194, 195, 196, 6, 197, 198],\n",
              " [4, 194, 195, 196, 6, 197, 198, 199],\n",
              " [200, 12],\n",
              " [200, 12, 201],\n",
              " [200, 12, 201, 202],\n",
              " [200, 12, 201, 202, 16],\n",
              " [200, 12, 201, 202, 16, 6],\n",
              " [200, 12, 201, 202, 16, 6, 203],\n",
              " [200, 12, 201, 202, 16, 6, 203, 36],\n",
              " [200, 12, 201, 202, 16, 6, 203, 36, 204],\n",
              " [200, 12, 201, 202, 16, 6, 203, 36, 204, 3],\n",
              " [200, 12, 201, 202, 16, 6, 203, 36, 204, 3, 205],\n",
              " [200, 12, 201, 202, 16, 6, 203, 36, 204, 3, 205, 206],\n",
              " [4, 8],\n",
              " [4, 8, 3],\n",
              " [4, 8, 3, 207],\n",
              " [4, 8, 3, 207, 208],\n",
              " [4, 8, 3, 207, 208, 30],\n",
              " [4, 8, 3, 207, 208, 30, 209],\n",
              " [4, 8, 3, 207, 208, 30, 209, 13],\n",
              " [4, 8, 3, 207, 208, 30, 209, 13, 210],\n",
              " [14, 211],\n",
              " [14, 211, 19],\n",
              " [14, 211, 19, 53],\n",
              " [14, 211, 19, 53, 1],\n",
              " [14, 211, 19, 53, 1, 212],\n",
              " [14, 211, 19, 53, 1, 212, 14],\n",
              " [14, 211, 19, 53, 1, 212, 14, 54],\n",
              " [2, 213],\n",
              " [2, 213, 6],\n",
              " [2, 213, 6, 214],\n",
              " [2, 213, 6, 214, 215],\n",
              " [2, 213, 6, 214, 215, 216],\n",
              " [2, 213, 6, 214, 215, 216, 217],\n",
              " [11, 8],\n",
              " [11, 8, 54],\n",
              " [11, 8, 54, 55],\n",
              " [11, 8, 54, 55, 218],\n",
              " [11, 8, 54, 55, 218, 6],\n",
              " [11, 8, 54, 55, 218, 6, 3],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55, 49],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55, 49, 219],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55, 49, 219, 7],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55, 49, 219, 7, 220],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55, 49, 219, 7, 220, 3],\n",
              " [11, 8, 54, 55, 218, 6, 3, 26, 55, 49, 219, 7, 220, 3, 221],\n",
              " [4, 8],\n",
              " [4, 8, 3],\n",
              " [4, 8, 3, 222],\n",
              " [4, 8, 3, 222, 223],\n",
              " [4, 8, 3, 222, 223, 6],\n",
              " [4, 8, 3, 222, 223, 6, 3],\n",
              " [4, 8, 3, 222, 223, 6, 3, 224],\n",
              " [4, 8, 3, 222, 223, 6, 3, 224, 5],\n",
              " [4, 8, 3, 222, 223, 6, 3, 224, 5, 225],\n",
              " [4, 8, 3, 222, 223, 6, 3, 224, 5, 225, 226],\n",
              " [11, 12],\n",
              " [11, 12, 7],\n",
              " [11, 12, 7, 20],\n",
              " [11, 12, 7, 20, 1],\n",
              " [11, 12, 7, 20, 1, 227],\n",
              " [11, 12, 7, 20, 1, 227, 32],\n",
              " [11, 12, 7, 20, 1, 227, 32, 48],\n",
              " [11, 12, 7, 20, 1, 227, 32, 48, 228],\n",
              " [11, 12, 7, 20, 1, 227, 32, 48, 228, 229],\n",
              " [2, 230],\n",
              " [2, 230, 29],\n",
              " [2, 230, 29, 231],\n",
              " [2, 230, 29, 231, 232],\n",
              " [2, 230, 29, 231, 232, 13],\n",
              " [2, 230, 29, 231, 232, 13, 3],\n",
              " [2, 230, 29, 231, 232, 13, 3, 233],\n",
              " [2, 230, 29, 231, 232, 13, 3, 233, 2],\n",
              " [2, 230, 29, 231, 232, 13, 3, 233, 2, 15],\n",
              " [2, 230, 29, 231, 232, 13, 3, 233, 2, 15, 29],\n",
              " [2, 230, 29, 231, 232, 13, 3, 233, 2, 15, 29, 234]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "cf517979-8e9e-4c01-9cd1-371f426a6e0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  56,  57],\n",
              "       [  0,   0,   0, ...,  56,  57,  34],\n",
              "       [  0,   0,   0, ...,  57,  34,  35],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 233,   2,  15],\n",
              "       [  0,   0,   0, ...,   2,  15,  29],\n",
              "       [  0,   0,   0, ...,  15,  29, 234]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "58077970-0754-4fa9-ca2a-01ec1f675c51"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "ab1dd4ff-44f1-4fac-c3d1-5c3ed860c611"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OL3vrEXSs_s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=235)"
      ],
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "4f1909dd-a439-43bf-a50e-da0da3802761"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380, 235)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(235, 100, input_length=15))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(235, activation='softmax'))"
      ],
      "metadata": {
        "id": "wo-OYfHpTK2o",
        "outputId": "11f3e0d3-0ef9-4d41-fb27-ed639ffa2416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-GGjqh7ue_Yq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "OxxXkrSXfIBv",
        "outputId": "5cbacbf0-15a7-495f-9375-056520793ec4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFUCALCfJRR",
        "outputId": "3c87f4f7-b442-41d1-a007-fb5d9d432c4a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.0167 - loss: 5.4561\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0686 - loss: 5.3477\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0555 - loss: 5.1158\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0537 - loss: 5.0799\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0427 - loss: 5.0879\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0664 - loss: 4.9695\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1024 - loss: 4.8176\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1077 - loss: 4.6415\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0948 - loss: 4.7205\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1023 - loss: 4.5728\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0746 - loss: 4.5801\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1012 - loss: 4.4354\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1116 - loss: 4.2404\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1249 - loss: 4.2025\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1746 - loss: 4.0255\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1688 - loss: 3.8659\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1881 - loss: 3.7781\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2269 - loss: 3.6156\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2202 - loss: 3.5053\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2618 - loss: 3.3390\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2943 - loss: 3.1182\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3777 - loss: 2.9292\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3826 - loss: 2.8174\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4059 - loss: 2.7141\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4628 - loss: 2.5727\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5165 - loss: 2.4157\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5079 - loss: 2.2821\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6161 - loss: 2.1009\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5963 - loss: 2.0776\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6395 - loss: 1.8443\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6839 - loss: 1.8479\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7234 - loss: 1.6568\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7246 - loss: 1.6122\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7445 - loss: 1.5413\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7816 - loss: 1.4734\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7815 - loss: 1.3779\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8222 - loss: 1.2886\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8376 - loss: 1.2504\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8126 - loss: 1.1747\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8368 - loss: 1.1611\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8619 - loss: 1.0435\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8642 - loss: 0.9982\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8779 - loss: 0.9480\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8765 - loss: 0.9791\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8896 - loss: 0.8867\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.8414\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8949 - loss: 0.8427\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9190 - loss: 0.7569\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.7142\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.7044\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8944 - loss: 0.6894\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.6440\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.5995\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.6317\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8735 - loss: 0.6271\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.5239\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9009 - loss: 0.5497\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9283 - loss: 0.5371\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.5871\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9018 - loss: 0.5192\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9237 - loss: 0.4423\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9146 - loss: 0.4716\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9017 - loss: 0.4643\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8958 - loss: 0.4743\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9035 - loss: 0.4341\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8986 - loss: 0.4487\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8942 - loss: 0.4531\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8856 - loss: 0.4617\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8932 - loss: 0.4187\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9008 - loss: 0.3683\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.3892\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.3983\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9053 - loss: 0.3889\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8999 - loss: 0.3810\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8820 - loss: 0.4107\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9213 - loss: 0.3348\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9005 - loss: 0.3821\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.3561\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.3488\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9068 - loss: 0.3485\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.3243\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8758 - loss: 0.3704\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9233 - loss: 0.2814\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9224 - loss: 0.2969\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8985 - loss: 0.3313\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8908 - loss: 0.3452\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9137 - loss: 0.3033\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9131 - loss: 0.2998\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9084 - loss: 0.3018\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8958 - loss: 0.3306\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9013 - loss: 0.3147\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9320 - loss: 0.2554\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9012 - loss: 0.3040\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8938 - loss: 0.3147\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9109 - loss: 0.2770\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9163 - loss: 0.2659\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9055 - loss: 0.2948\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9201 - loss: 0.2688\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8936 - loss: 0.3105\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9093 - loss: 0.2625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x792eab0ec6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "text = \"I told\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGeYGwCMfTus",
        "outputId": "b1a7c318-24a5-4fc7-bfa5-4b8e91d695e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "I told my\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "I told my wife\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "I told my wife she\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "I told my wife she she\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "I told my wife she she was\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "I told my wife she she was drawing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "I told my wife she she was drawing drawing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "I told my wife she she was drawing drawing drawing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "I told my wife she she was drawing drawing drawing drawing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "I told my wife she she was drawing drawing drawing drawing her\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTxsj-_CjbQW",
        "outputId": "652847ac-4c33-48ef-9f09-d799e6b060dd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 1,\n",
              " 'i': 2,\n",
              " 'the': 3,\n",
              " 'why': 4,\n",
              " 'it': 5,\n",
              " 'to': 6,\n",
              " 'you': 7,\n",
              " 'did': 8,\n",
              " 'was': 9,\n",
              " 'on': 10,\n",
              " 'what': 11,\n",
              " 'do': 12,\n",
              " 'of': 13,\n",
              " 'in': 14,\n",
              " 'don’t': 15,\n",
              " 'up': 16,\n",
              " 'my': 17,\n",
              " 'i’m': 18,\n",
              " 'he': 19,\n",
              " 'call': 20,\n",
              " 'told': 21,\n",
              " 'an': 22,\n",
              " 'used': 23,\n",
              " 'now': 24,\n",
              " 'over': 25,\n",
              " 'other': 26,\n",
              " 'be': 27,\n",
              " 'and': 28,\n",
              " 'know': 29,\n",
              " 'two': 30,\n",
              " 'then': 31,\n",
              " 'with': 32,\n",
              " 'me': 33,\n",
              " 'have': 34,\n",
              " 'so': 35,\n",
              " 'they': 36,\n",
              " 'she': 37,\n",
              " 'too': 38,\n",
              " 'tell': 39,\n",
              " 'joke': 40,\n",
              " 'but': 41,\n",
              " 'about': 42,\n",
              " \"can't\": 43,\n",
              " 'hear': 44,\n",
              " 'cheese': 45,\n",
              " 'book': 46,\n",
              " 'each': 47,\n",
              " 'no': 48,\n",
              " 'i’ll': 49,\n",
              " 'made': 50,\n",
              " 'see': 51,\n",
              " 'needed': 52,\n",
              " 'got': 53,\n",
              " 'one': 54,\n",
              " 'wall': 55,\n",
              " 'parallel': 56,\n",
              " 'lines': 57,\n",
              " 'much': 58,\n",
              " 'common': 59,\n",
              " 'it’s': 60,\n",
              " 'shame': 61,\n",
              " 'scientists': 62,\n",
              " 'trust': 63,\n",
              " 'atoms': 64,\n",
              " 'make': 65,\n",
              " 'stuff': 66,\n",
              " 'wife': 67,\n",
              " 'drawing': 68,\n",
              " 'her': 69,\n",
              " 'eyebrows': 70,\n",
              " 'high': 71,\n",
              " 'looked': 72,\n",
              " 'surprised': 73,\n",
              " 'would': 74,\n",
              " 'construction': 75,\n",
              " 'working': 76,\n",
              " 'scarecrow': 77,\n",
              " 'win': 78,\n",
              " 'award': 79,\n",
              " 'outstanding': 80,\n",
              " 'play': 81,\n",
              " 'piano': 82,\n",
              " 'by': 83,\n",
              " 'ear': 84,\n",
              " 'use': 85,\n",
              " 'hands': 86,\n",
              " 'fake': 87,\n",
              " 'spaghetti': 88,\n",
              " 'impasta': 89,\n",
              " 'dog': 90,\n",
              " 'bones': 91,\n",
              " 'chewed': 92,\n",
              " 'pterodactyl': 93,\n",
              " 'bathroom': 94,\n",
              " 'because': 95,\n",
              " '“p”': 96,\n",
              " 'is': 97,\n",
              " 'silent': 98,\n",
              " 'that': 99,\n",
              " \"isn't\": 100,\n",
              " 'yours': 101,\n",
              " 'nacho': 102,\n",
              " \"i'm\": 103,\n",
              " 'reading': 104,\n",
              " 'anti': 105,\n",
              " 'gravity': 106,\n",
              " \"it's\": 107,\n",
              " 'impossible': 108,\n",
              " 'put': 109,\n",
              " 'down': 110,\n",
              " 'skeletons': 111,\n",
              " 'fight': 112,\n",
              " 'guts': 113,\n",
              " 'addicted': 114,\n",
              " 'soap': 115,\n",
              " 'clean': 116,\n",
              " 'eggs': 117,\n",
              " 'jokes': 118,\n",
              " 'they’d': 119,\n",
              " 'crack': 120,\n",
              " 'ordered': 121,\n",
              " 'chicken': 122,\n",
              " 'egg': 123,\n",
              " 'online': 124,\n",
              " 'let': 125,\n",
              " \"what's\": 126,\n",
              " 'orange': 127,\n",
              " 'sounds': 128,\n",
              " 'like': 129,\n",
              " 'parrot': 130,\n",
              " 'carrot': 131,\n",
              " 'bicycle': 132,\n",
              " 'fall': 133,\n",
              " 'tired': 134,\n",
              " 'fear': 135,\n",
              " 'speed': 136,\n",
              " 'bumps': 137,\n",
              " 'slowly': 138,\n",
              " 'getting': 139,\n",
              " 'your': 140,\n",
              " 'nose': 141,\n",
              " '12': 142,\n",
              " 'inches': 143,\n",
              " 'long': 144,\n",
              " 'it’d': 145,\n",
              " 'foot': 146,\n",
              " 'pencil': 147,\n",
              " 'erasers': 148,\n",
              " 'pointless': 149,\n",
              " 'stayed': 150,\n",
              " 'all': 151,\n",
              " 'night': 152,\n",
              " 'where': 153,\n",
              " 'sun': 154,\n",
              " 'went': 155,\n",
              " 'dawned': 156,\n",
              " 'math': 157,\n",
              " 'look': 158,\n",
              " 'sad': 159,\n",
              " 'many': 160,\n",
              " 'problems': 161,\n",
              " 'computer': 162,\n",
              " 'break': 163,\n",
              " 'won’t': 164,\n",
              " 'stop': 165,\n",
              " 'sending': 166,\n",
              " 'beach': 167,\n",
              " 'photos': 168,\n",
              " 'hate': 169,\n",
              " 'facial': 170,\n",
              " 'hair': 171,\n",
              " 'grew': 172,\n",
              " 'coffee': 173,\n",
              " 'file': 174,\n",
              " 'police': 175,\n",
              " 'report': 176,\n",
              " 'mugged': 177,\n",
              " 'belt': 178,\n",
              " 'watches': 179,\n",
              " 'waist': 180,\n",
              " 'time': 181,\n",
              " 'claustrophobic': 182,\n",
              " 'astronaut': 183,\n",
              " 'little': 184,\n",
              " 'space': 185,\n",
              " 'stadium': 186,\n",
              " 'cool': 187,\n",
              " 'filled': 188,\n",
              " 'fans': 189,\n",
              " 'seafood': 190,\n",
              " 'diet': 191,\n",
              " 'food': 192,\n",
              " 'eat': 193,\n",
              " \"don't\": 194,\n",
              " 'crabs': 195,\n",
              " 'give': 196,\n",
              " 'charity': 197,\n",
              " 'they’re': 198,\n",
              " 'shellfish': 199,\n",
              " 'how': 200,\n",
              " 'cows': 201,\n",
              " 'stay': 202,\n",
              " 'date': 203,\n",
              " 'read': 204,\n",
              " 'moos': 205,\n",
              " 'paper': 206,\n",
              " 'golfer': 207,\n",
              " 'bring': 208,\n",
              " 'pairs': 209,\n",
              " 'pants': 210,\n",
              " 'case': 211,\n",
              " 'hole': 212,\n",
              " 'tried': 213,\n",
              " 'catch': 214,\n",
              " 'fog': 215,\n",
              " 'yesterday': 216,\n",
              " 'mist': 217,\n",
              " 'say': 218,\n",
              " 'meet': 219,\n",
              " 'at': 220,\n",
              " 'corner': 221,\n",
              " 'cookie': 222,\n",
              " 'go': 223,\n",
              " 'hospital': 224,\n",
              " 'felt': 225,\n",
              " 'crummy': 226,\n",
              " 'fish': 227,\n",
              " 'eyes': 228,\n",
              " 'fsh': 229,\n",
              " 'only': 230,\n",
              " '25': 231,\n",
              " 'letters': 232,\n",
              " 'alphabet': 233,\n",
              " 'y': 234}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92y7gE6pj9EZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}